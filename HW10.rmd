---
output:
  html_document: default
  pdf_document: default
---
# Intro to Data Science - HW 10

##### Copyright 2021, Jeffrey Stanton, Jeffrey Saltz, and Jasmina Tacheva


```{r}
# Enter your name here: Yunhan Zhang
```

### Attribution statement: (choose only one and delete the rest)


```{r}
# 1. I did this homework by myself, with help from the book and the professor.
```

**Association mining** can be applied to many data problems beyond the well-known example of **finding relationships between different products in customer shopping data**. In this homework assignment, we will explore **real data** from the banking sector and look for **patterns associated with the likelihood of responding positively to a direct marketing campaign and signing up for a term deposit with the bank (stored in the variable “y”)**. <br>
You can find out more about the variables in this dataset here: https://archive.ics.uci.edu/ml/datasets/bank+marketing

## Part 1: Explore Data Set

A.	Read the contents of the following URL to a dataframe called **bank** <br>
https://intro-datascience.s3.us-east-2.amazonaws.com/bank-full.csv

**Hint**: Even though this is a .csv file, chances are R won’t be able to read it in correctly using the read_csv() function. If you take a closer look at the contents of the URL file, you may notice each field is separated by a **semicolon** (;) rather than a comma. 

In situations like this, consider using either read.csv or read.table, with two additional parameters. *sep=";"* defines how the data is seperated (the default is a comma), and *header=TRUE* defines that there is a header line in the dataset. 


```{r}
bank <- read.csv("https://intro-datascience.s3.us-east-2.amazonaws.com/bank-full.csv", header = TRUE, sep = ";")
```

Make sure there are **41,188** rows and **21** columns in your **bank** df.


```{r}
dim(bank)
```

B.	Next, we will focus on some key factor variables from the dataset, and convert a few numeric ones to factor variables. Execute the following command.  Write a comment describing how the conversion for each numeric variable works and what are the variables in the resulting dataframe.


```{r}
bank_new <- data.frame(job=as.factor(bank$job),
                     marital=as.factor(bank$marital),
                     housing_loan=as.factor(bank$housing),
                     young=as.factor(bank$age<median(bank$age)),
                     contacted_more_than_once=as.factor(bank$campaign>1),
                     contacted_before_this_campaign=as.factor(bank$previous<0),
                     success=as.factor(bank$y))
library(tidyverse)
view(bank_new)
# By using view() can let me better look at the new data frame. Jobs/Marital/Housing_loan/Success are from the origin data frame. Young: False is any ages that are less or equal to the age's median; True is higher than age's median. Contacted_more_than_once: False is campaign less or equal to 1 and True is bigger than 1; Contacted_before_this_campaign: False is previous smaller than 0 and True is previous bigger than 0.
```

C.	Count the number of successful term deposit sign-ups, using the table( ) command on the **success** variable.


```{r}
table(bank_new$success)
```

D.	Express the results of problem C as percentages by sending the results of the table( ) command into the prop.table( ) command.


```{r}
prop.table(table(bank_new$success))
```

E.	Using the same techniques, show the percentages for the **marital** and **housing_loan** variables as well.


```{r}
prop.table(table(bank_new$marital))
prop.table(table(bank_new$housing_loan))
```

## Part 2: Coerce the data frame into transactions

F.	Install and library two packages: **arules** and **arulesViz**.


```{r}
library(arules)
library(arulesViz)
```

G.	Coerce the **bank_new** dataframe into a **sparse transactions matrix** called **bankX**.


```{r}
bankX <- as(bank_new, "transactions")
```

H.	Use the itemFrequency( ) and itemFrequencyPlot( ) commands to explore the contents of **bankX**. What do you see?


```{r}
itemFrequency(bankX)
itemFrequencyPlot(bankX)
# There are several useful information that we can get from these: Among all the jobs, admin and blue-collar have the most frequencies. And most of them are married. Most of them have housing loan. Ages are likely equal to each other. Number of contacted_more_than_once are different but very close. All of the clients does not contact before this campaign. Finally, most of them who failed to sign up for a term deposit, only few people who successfully signed up for a term deposit.
```

I.	This is a fairly large dataset, so we will explore only the first 10 observations in the **bankX** transaction matrix: 


```{r}
inspect(bankX[1:10]) 
```

Explain the difference between **bank_new** and **bankX** in a block comment:


```{r}
# By using sparse transactions matrix, it can help us better understand each item's frequency. More so, we can use rules to explore the data.
```

## Part 3: Use arules to discover patterns

**Support** is the proportion of times that a particular set of items occurs relative to the whole dataset. <br>
**Confidence** is proportion of times that the consequent occurs when the antecedent is present. <br>

J.	Use **apriori** to generate a set of rules with support over 0.005 and confidence over 0.3, and trying to predict who successfully signed up for a term deposit. <br>
**Hint:** You need to define the **right-hand side rule (rhs)**.


```{r}
ruleset <- apriori(bankX, parameter=list(supp=0.005, conf=0.3), control=list(verbose=F), 
                  appearance=list(default="lhs",rhs=("success=yes")))
```

K.	Use inspect() to review of the **ruleset**. 


```{r}
inspect(ruleset)
```

L.	Use the output of inspect( ) or inspectDT( ) and describe **any 2 rules** the algorithm found.  


```{r}
inspectDT(ruleset)
# [2]: For successfully applied students that are single / total transactions is near 0.64% & For successfully applied students that are single / total number of single students is near 32%.
# [5]: For successfully applied students that are single and young / total transactions is near 0.63% & For successfully applied students that are single and young / total number of single and young students is near 32%.
```
